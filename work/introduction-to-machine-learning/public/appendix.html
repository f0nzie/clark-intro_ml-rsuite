<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Appendix | Machine Learning</title>
  <meta name="description" content="This document provides an introduction to machine learning for applied researchers. While conceptual in nature, demonstrations are provided for several common machine learning approaches of a supervised nature. In addition, all the R examples, which utilize the caret package, are also provided in Python via scikit-learn." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Appendix | Machine Learning" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://m-clark.github.io/introduction-to-machine-learning/" />
  <meta property="og:image" content="https://m-clark.github.io/introduction-to-machine-learning/img/nineteeneightyR.png" />
  <meta property="og:description" content="This document provides an introduction to machine learning for applied researchers. While conceptual in nature, demonstrations are provided for several common machine learning approaches of a supervised nature. In addition, all the R examples, which utilize the caret package, are also provided in Python via scikit-learn." />
  <meta name="github-repo" content="m-clark/introduction-to-machine-learning/" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Appendix | Machine Learning" />
  
  <meta name="twitter:description" content="This document provides an introduction to machine learning for applied researchers. While conceptual in nature, demonstrations are provided for several common machine learning approaches of a supervised nature. In addition, all the R examples, which utilize the caret package, are also provided in Python via scikit-learn." />
  <meta name="twitter:image" content="https://m-clark.github.io/introduction-to-machine-learning/img/nineteeneightyR.png" />



<meta name="date" content="2019-06-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="other.html">
<link rel="next" href="references.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.6/datatables.js"></script>
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.16/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.16/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<script src="libs/d3-3.5.3/./d3.min.js"></script>
<link href="libs/d3heatmapcore-0.0.0/heatmapcore.css" rel="stylesheet" />
<script src="libs/d3heatmapcore-0.0.0/heatmapcore.js"></script>
<script src="libs/d3-tip-0.6.6/index.js"></script>
<script src="libs/d3heatmap-binding-0.6.1.2/d3heatmap.js"></script>
<script src="libs/plotly-binding-4.9.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.46.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.46.1/plotly-latest.min.js"></script>
<script src="libs/viz-0.3/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.1/grViz.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/book.css" type="text/css" />
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class='before'><a href="./">Machine Learning</a></li>

<li class="divider"></li>
<li><a href="index.html#section"></a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i>Introduction</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#explanation-prediction"><i class="fa fa-check"></i>Explanation &amp; Prediction</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#terminology"><i class="fa fa-check"></i>Terminology</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#supervised-vs.unsupervised"><i class="fa fa-check"></i>Supervised vs.Â Unsupervised</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#tools-you-already-have"><i class="fa fa-check"></i>Tools you already have</a><ul>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#the-standard-linear-model"><i class="fa fa-check"></i>The Standard Linear Model</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#logistic-regression"><i class="fa fa-check"></i>Logistic Regression</a></li>
<li class="chapter" data-level="" data-path="intro.html"><a href="intro.html#expansions-of-those-tools"><i class="fa fa-check"></i>Expansions of Those Tools</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html"><i class="fa fa-check"></i>Concepts</a><ul>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#loss-functions"><i class="fa fa-check"></i>Loss Functions</a><ul>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#continuous-outcomes"><i class="fa fa-check"></i>Continuous Outcomes</a></li>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#categorical-outcomes"><i class="fa fa-check"></i>Categorical Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#regularization"><i class="fa fa-check"></i>Regularization</a><ul>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#r-example-1"><i class="fa fa-check"></i>R Example</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#bias-variance-tradeoff"><i class="fa fa-check"></i>Bias-Variance Tradeoff</a><ul>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#bias-variance"><i class="fa fa-check"></i>Bias &amp; Variance</a></li>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#the-tradeoff"><i class="fa fa-check"></i>The Tradeoff</a></li>
<li><a href="concepts.html#diagnosing-bias-variance-issues-possible-solutions">Diagnosing Bias-Variance Issues <em>&amp;</em> Possible Solutions</a></li>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#bias-variance-summary"><i class="fa fa-check"></i>Bias-Variance Summary</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#cross-validation"><i class="fa fa-check"></i>Cross-Validation</a><ul>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#adding-another-validation-set"><i class="fa fa-check"></i>Adding Another Validation Set</a></li>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#k-fold-cross-validation"><i class="fa fa-check"></i>K-fold Cross-Validation</a></li>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#bootstrap"><i class="fa fa-check"></i>Bootstrap</a></li>
<li class="chapter" data-level="" data-path="concepts.html"><a href="concepts.html#other-stuff"><i class="fa fa-check"></i>Other Stuff</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html"><i class="fa fa-check"></i>Opening the Black Box</a><ul>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#process-overview"><i class="fa fa-check"></i>Process Overview</a><ul>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#data-preparation"><i class="fa fa-check"></i>Data Preparation</a></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#model-selection"><i class="fa fa-check"></i>Model Selection</a></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#model-assessment"><i class="fa fa-check"></i>Model Assessment</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#the-dataset"><i class="fa fa-check"></i>The Dataset</a></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#r-implementation"><i class="fa fa-check"></i>R Implementation</a></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#feature-selection-the-data-partition"><i class="fa fa-check"></i>Feature Selection &amp; The Data Partition</a></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#regularized-regression"><i class="fa fa-check"></i>Regularized Regression</a><ul>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#strengths-weaknesses"><i class="fa fa-check"></i>Strengths &amp; Weaknesses</a></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#final-thoughts"><i class="fa fa-check"></i>Final Thoughts</a></li>
</ul></li>
<li><a href="blackbox.html#k-nearest-neighbors"><span class="math inline">\(k\)</span>-nearest Neighbors</a><ul>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#strengths-weaknesses-1"><i class="fa fa-check"></i>Strengths &amp; Weaknesses</a></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#final-thoughts-1"><i class="fa fa-check"></i>Final Thoughts</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#neural-networks"><i class="fa fa-check"></i>Neural Networks</a><ul>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#strengths-weaknesses-2"><i class="fa fa-check"></i>Strengths &amp; Weaknesses</a></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#final-thoughts-2"><i class="fa fa-check"></i>Final Thoughts</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#trees-forests"><i class="fa fa-check"></i>Trees &amp; Forests</a><ul>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#understanding-the-results"><i class="fa fa-check"></i>Understanding the Results</a></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#strengths-weaknesses-3"><i class="fa fa-check"></i>Strengths &amp; Weaknesses</a></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#final-thoughts-3"><i class="fa fa-check"></i>Final Thoughts</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#support-vector-machines"><i class="fa fa-check"></i>Support Vector Machines</a><ul>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#strengths-weaknesses-4"><i class="fa fa-check"></i>Strengths &amp; Weaknesses</a></li>
<li class="chapter" data-level="" data-path="blackbox.html"><a href="blackbox.html#final-thoughts-4"><i class="fa fa-check"></i>Final Thoughts</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html"><i class="fa fa-check"></i>Wrap-up</a><ul>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#unsupervised-learning"><i class="fa fa-check"></i>Unsupervised Learning</a><ul>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#clustering"><i class="fa fa-check"></i>Clustering</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#latent-variable-models"><i class="fa fa-check"></i>Latent Variable Models</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#graphical-structure"><i class="fa fa-check"></i>Graphical Structure</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#imputation"><i class="fa fa-check"></i>Imputation</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#ensembles"><i class="fa fa-check"></i>Ensembles</a><ul>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#bagging"><i class="fa fa-check"></i>Bagging</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#boosting"><i class="fa fa-check"></i>Boosting</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#stacking"><i class="fa fa-check"></i>Stacking</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#deep-learning"><i class="fa fa-check"></i>Deep Learning</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#feature-selection-importance"><i class="fa fa-check"></i>Feature Selection &amp; Importance</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#natural-language-processingtext-analysis"><i class="fa fa-check"></i>Natural Language Processing/Text Analysis</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#bayesian-approaches"><i class="fa fa-check"></i>Bayesian Approaches</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#more-stuff"><i class="fa fa-check"></i>More Stuff</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#summary"><i class="fa fa-check"></i>Summary</a><ul>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#cautionary-notes"><i class="fa fa-check"></i>Cautionary Notes</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#some-guidelines"><i class="fa fa-check"></i>Some Guidelines</a></li>
<li class="chapter" data-level="" data-path="other.html"><a href="other.html#conclusion"><i class="fa fa-check"></i>Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i>Appendix</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#bias-variance-demo"><i class="fa fa-check"></i>Bias Variance Demo</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#programming-languages"><i class="fa fa-check"></i>Programming Languages</a><ul>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#r"><i class="fa fa-check"></i>R</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#python"><i class="fa fa-check"></i>Python</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#other"><i class="fa fa-check"></i>Other</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#local-interpretable-model-agnostic-explanations"><i class="fa fa-check"></i>Local Interpretable Model-agnostic Explanations</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#various-variable-importance-measures"><i class="fa fa-check"></i>Various Variable Importance Measures</a></li>
<li class="chapter" data-level="" data-path="appendix.html"><a href="appendix.html#brief-glossary-of-common-terms"><i class="fa fa-check"></i>Brief Glossary of Common Terms</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li class='after'">
   <a href="https://m-clark.github.io/">
      <img src="img/mc_logo.png" style="width:25%; padding:0px 0; display:block; margin: 0 auto;" alt="MC logo">
   </a>
</li>
<li class='after'">
   <div style='text-align:center'>
      <a href="https://github.com/m-clark/">
         <i class="fab fa-github fa-2x" aria-hidden="true"></i>
      </a>
   </div>
</li>
<li class='after'">
   <div style='text-align:center'>
      <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
         <i class="fab fa-creative-commons fa-lg"></i>
         <i class="fab fa-creative-commons-by fa-lg"></i>
         <i class="fab fa-creative-commons-sa fa-lg"></i>
      </a>
   </div>
</li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="appendix" class="section level1">
<h1>Appendix</h1>
<div id="bias-variance-demo" class="section level2">
<h2>Bias Variance Demo</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">123</span>)
x =<span class="st"> </span><span class="kw">runif</span>(<span class="dv">1000</span>)
ytrue =<span class="st"> </span><span class="kw">sin</span>(<span class="dv">3</span><span class="op">*</span>pi<span class="op">*</span>x)
basedat =<span class="st"> </span><span class="kw">cbind</span>(x,ytrue)[<span class="kw">order</span>(x),]
 
gendatfunc =<span class="st"> </span><span class="cf">function</span>(<span class="dt">noise=</span>.<span class="dv">5</span>, <span class="dt">n=</span><span class="dv">1000</span>){
  x =<span class="st"> </span><span class="kw">runif</span>(n)
  y =<span class="st"> </span><span class="kw">sin</span>(<span class="dv">3</span><span class="op">*</span>pi<span class="op">*</span>x) <span class="op">+</span><span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dt">sd=</span>noise) <span class="co"># truth</span>
  d =<span class="st"> </span><span class="kw">cbind</span>(x, y)
  d
}
 
gendat =<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">100</span>, <span class="kw">gendatfunc</span>(<span class="dt">n=</span><span class="dv">100</span>))
<span class="kw">str</span>(gendat)
 
<span class="kw">library</span>(kernlab)
 
rbf1 =<span class="st"> </span><span class="kw">apply</span>(gendat, <span class="dv">3</span>, 
             <span class="cf">function</span>(d) <span class="kw">predict</span>(<span class="kw">gausspr</span>(y<span class="op">~</span>x, <span class="dt">data=</span><span class="kw">data.frame</span>(d), <span class="dt">kpar=</span><span class="kw">list</span>(<span class="dt">sigma=</span>.<span class="dv">5</span>)), 
                                 <span class="dt">newdata =</span> <span class="kw">data.frame</span>(x), <span class="dt">type=</span><span class="st">&#39;response&#39;</span>))
rbf2 =<span class="st"> </span><span class="kw">apply</span>(gendat, <span class="dv">3</span>, 
             <span class="cf">function</span>(d) <span class="kw">predict</span>(<span class="kw">gausspr</span>(y<span class="op">~</span>x, <span class="dt">data=</span><span class="kw">data.frame</span>(d)), 
                                 <span class="dt">newdata =</span> <span class="kw">data.frame</span>(x), <span class="dt">type=</span><span class="st">&#39;response&#39;</span>) )
 
<span class="kw">library</span>(ggplot2); <span class="kw">library</span>(tidyverse); <span class="kw">library</span>(gridExtra)
 
rbf1_samp =<span class="st"> </span>rbf1 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>data.frame <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cbind</span>(x, .) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">slice</span>(<span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="dv">25</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(<span class="dt">key=</span>sample, <span class="dt">value=</span>yhat, <span class="op">-</span>x)
 
rbf2_samp =<span class="st"> </span>rbf2 <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span>data.frame <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">cbind</span>(x, .) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">slice</span>(<span class="kw">sample</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>, <span class="dv">25</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">gather</span>(<span class="dt">key=</span>sample, <span class="dt">value=</span>yhat, <span class="op">-</span>x)
 
g1 =<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span><span class="kw">data.frame</span>(basedat)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_blank</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>yhat, <span class="dt">group=</span>sample), <span class="dt">color=</span><span class="st">&#39;#ff5500&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">25</span>, <span class="dt">data=</span>rbf1_samp) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&#39;&#39;</span>, <span class="dt">title=</span><span class="st">&#39;Low Variance&#39;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span>lazerhawk<span class="op">::</span><span class="kw">theme_trueMinimal</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(
    <span class="dt">legend.key =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill=</span><span class="st">&#39;#fffff8&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>),
    <span class="dt">legend.background =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill=</span><span class="st">&#39;#fffff8&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>),
    <span class="dt">panel.background =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">panel.grid =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">strip.background =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">plot.background =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;#fffff8&quot;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>)
  )
 
g2 =<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span><span class="kw">data.frame</span>(basedat)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>ytrue), <span class="dt">color=</span><span class="st">&#39;#00aaff&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>yhat), <span class="dt">color=</span><span class="st">&#39;#ff5500&#39;</span>, <span class="kw">data.frame</span>(<span class="dt">yhat=</span><span class="kw">rowMeans</span>(rbf1))) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&#39;&#39;</span>, <span class="dt">title=</span><span class="st">&#39;High Bias&#39;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span>lazerhawk<span class="op">::</span><span class="kw">theme_trueMinimal</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(
    <span class="dt">legend.key =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill=</span><span class="st">&#39;#fffff8&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>),
    <span class="dt">legend.background =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill=</span><span class="st">&#39;#fffff8&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>),
    <span class="dt">panel.background =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">panel.grid =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">strip.background =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">plot.background =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;#fffff8&quot;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>)
  )
 
g3 =<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span><span class="kw">data.frame</span>(basedat)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_blank</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>yhat, <span class="dt">group=</span>sample), <span class="dt">color=</span><span class="st">&#39;#ff5500&#39;</span>, <span class="dt">alpha=</span>.<span class="dv">25</span>, <span class="dt">data=</span>rbf2_samp) <span class="op">+</span>
<span class="st">    </span><span class="kw">ylim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&#39;&#39;</span>, <span class="dt">title=</span><span class="st">&#39;High Variance&#39;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span>lazerhawk<span class="op">::</span><span class="kw">theme_trueMinimal</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(
    <span class="dt">legend.key =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill=</span><span class="st">&#39;#fffff8&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>),
    <span class="dt">legend.background =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill=</span><span class="st">&#39;#fffff8&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>),
    <span class="dt">panel.background =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">panel.grid =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">strip.background =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">plot.background =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;#fffff8&quot;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>)
  )
 
g4 =<span class="st"> </span><span class="kw">ggplot</span>(<span class="dt">data=</span><span class="kw">data.frame</span>(basedat)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>ytrue), <span class="dt">color=</span><span class="st">&#39;#00aaff&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>yhat), <span class="dt">color=</span><span class="st">&#39;#ff5500&#39;</span>, <span class="kw">data.frame</span>(<span class="dt">yhat=</span><span class="kw">rowMeans</span>(rbf2))) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylim</span>(<span class="kw">c</span>(<span class="op">-</span><span class="fl">1.5</span>, <span class="fl">1.5</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="st">&#39;&#39;</span>, <span class="dt">title=</span><span class="st">&#39;Low Bias&#39;</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span>lazerhawk<span class="op">::</span><span class="kw">theme_trueMinimal</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(
    <span class="dt">legend.key =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill=</span><span class="st">&#39;#fffff8&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>),
    <span class="dt">legend.background =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill=</span><span class="st">&#39;#fffff8&#39;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>),
    <span class="dt">panel.background =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">panel.grid =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">strip.background =</span> ggplot2<span class="op">::</span><span class="kw">element_blank</span>(),
    <span class="dt">plot.background =</span> ggplot2<span class="op">::</span><span class="kw">element_rect</span>(<span class="dt">fill =</span> <span class="st">&quot;#fffff8&quot;</span>, <span class="dt">colour =</span> <span class="ot">NA</span>)
  )
 
<span class="kw">grid.arrange</span>(g1, g2, g3, g4, <span class="dt">ncol=</span><span class="dv">2</span>)</code></pre>
</div>
<div id="programming-languages" class="section level2">
<h2>Programming Languages</h2>
<div id="r" class="section level3">
<h3>R</h3>
<p>Demonstrations for this document were done with R, and specifically the <span class="pack">caret</span> package. I would highly recommend using it for your own needs, as it makes a lot the ML process simpler, while providing access to whatever technique you want to use, even while it comes with the ability to use hundreds of approaches out of the box.</p>
<div id="deep-learning-example" class="section level4">
<h4>Deep learning example</h4>
<p>The following is a deep learning example using the same data from the previous examples, using <span class="pack">keras</span>. The package is an R wrapper for the <span class="pack">keras</span> module in Python, which itself is a wrapper for <span class="pack">tensorflow</span>. For more on using TensorFlow with R, check out <a href="https://tensorflow.rstudio.com/">RStudioâs documentation</a>.</p>
<p>This is a <span class="emph">sequential neural net</span> with three layers. I also add some <span class="emph">dropout</span> at each layer, which, given the material presented, you can think of as a means of regularization to avoid overfitting<a href="#fn59" class="footnote-ref" id="fnref59"><sup>59</sup></a>. Note that keras works a bit differently, in that its objects are mutable, hence the there is no reassignment of the <span class="objclass">model</span>. This R implementation also provides some nice visualizations to keep your interest while it runs.</p>
<p>This is just a starting point, so donât expect any better performance than those shown previously, but itâll give you something to play with. Note that there is plenty to learn, and such models require copious amounts of tuning to work well.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(keras)

X_train =<span class="st"> </span><span class="kw">model.matrix</span>(<span class="kw">lm</span>(good <span class="op">~</span><span class="st"> </span>. <span class="dv">-1</span>, <span class="dt">data=</span>wine_train)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">scale</span>()
y_train =<span class="st"> </span><span class="kw">as.numeric</span>(wine_train<span class="op">$</span>good) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>
X_test =<span class="st"> </span><span class="kw">model.matrix</span>(<span class="kw">lm</span>(good <span class="op">~</span><span class="st"> </span>. <span class="dv">-1</span>, <span class="dt">data=</span>wine_test)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">scale</span>()
y_test =<span class="st"> </span><span class="kw">as.numeric</span>(wine_test<span class="op">$</span>good) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>

model =<span class="st"> </span><span class="kw">keras_model_sequential</span>() 

model <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">256</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>, <span class="dt">input_shape =</span> <span class="kw">c</span>(<span class="dv">9</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.4</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">128</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.3</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">64</span>, <span class="dt">activation =</span> <span class="st">&#39;relu&#39;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.2</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1</span>, <span class="dt">activation =</span> <span class="st">&#39;sigmoid&#39;</span>)

<span class="kw">summary</span>(model)

model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">compile</span>(
  <span class="dt">optimizer =</span> <span class="st">&#39;nadam&#39;</span>,
  <span class="dt">loss =</span> <span class="st">&quot;binary_crossentropy&quot;</span>,
  <span class="dt">metrics =</span> <span class="st">&quot;accuracy&quot;</span>
)

history =<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">fit</span>(X_train, 
      y_train, 
      <span class="dt">epochs =</span> <span class="dv">10000</span>, 
      <span class="dt">validation_split =</span> <span class="fl">0.1</span>,
      <span class="dt">verbose =</span> <span class="dv">1</span>,
      <span class="dt">view_metrics =</span> <span class="dv">1</span>)

<span class="kw">plot</span>(history)

<span class="co"># model %&gt;% evaluate(X_test, y_test)</span>

ypred =<span class="st"> </span>model <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">predict_classes</span>(X_test)
caret<span class="op">::</span><span class="kw">confusionMatrix</span>(ypred, y_test, <span class="dt">positive=</span><span class="st">&#39;1&#39;</span>)</code></pre>
</div>
</div>
<div id="python" class="section level3">
<h3>Python</h3>
<p>If your data fits on your machine and/or your analysis time is less than a couple hours, R is hands down the easiest to use to go from data to document, including if that document is an interactive website. That said, R probably isnât even the most popular ML tool, because in many situations we have a lot more data, or simply need the predictions without frills and as fast as possible<a href="#fn60" class="footnote-ref" id="fnref60"><sup>60</sup></a>. As such Python is the de facto standard in such situations, and probably the most popular development environment for machine learning.</p>
<p>One can start with the <span class="pack">scikit-learn</span> module, using it much in the same way as was demonstrated with <span class="pack">caret</span>. It will get you very far, but for some situations, you may need more heavy-duty options like <span class="pack">tensorflow</span>, <span class="pack">pytorch</span>, etc.</p>
<!-- Though no change was made to the code, nor any need to re-evaluate what was alrady displayed, something caused knitr to do so and empty lines are now ignored; separate chunks until fixed -->
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> pandas <span class="im">as</span> pd
<span class="im">import</span> numpy <span class="im">as</span> np
<span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split
<span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler
<span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier
<span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, accuracy_score
<span class="co"># from os import chdir            # if desired</span>
<span class="co"># chdir(&#39;your_directory&#39;)</span></code></pre>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># import data</span>
wine <span class="op">=</span> pd.read_csv(<span class="st">&#39;data/wine.csv&#39;</span>)</code></pre>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># data preprocessing</span>
np.random.seed(<span class="dv">1234</span>)
X <span class="op">=</span> wine.drop([<span class="st">&#39;free.sulfur.dioxide&#39;</span>, <span class="st">&#39;density&#39;</span>, <span class="st">&#39;quality&#39;</span>, <span class="st">&#39;color&#39;</span>, <span class="st">&#39;white&#39;</span>,<span class="st">&#39;good&#39;</span>], axis<span class="op">=</span><span class="dv">1</span>)
X <span class="op">=</span> MinMaxScaler().fit_transform(X)  <span class="co"># by default on 0, 1 scale</span>
y <span class="op">=</span> wine[<span class="st">&#39;good&#39;</span>]
X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.2</span>)</code></pre>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># train model</span>
rf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">1000</span>)
rf_train <span class="op">=</span> rf.fit(X_train, y_train)</code></pre>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># get test predictions</span>
rf_predict <span class="op">=</span> rf_train.predict(X_test)</code></pre>
<pre class="sourceCode python"><code class="sourceCode python"><span class="co"># create confusion matrix, and accuracy</span>
cm <span class="op">=</span> confusion_matrix(y_test,rf_predict)
cm_prob <span class="op">=</span> cm <span class="op">/</span> np.<span class="bu">sum</span>(cm)  <span class="co"># as probs</span>
<span class="bu">print</span>(cm_prob)</code></pre>
<pre><code>[[0.26692308 0.09076923]
 [0.07461538 0.56769231]]</code></pre>
<pre class="sourceCode python"><code class="sourceCode python">acc <span class="op">=</span> accuracy_score(y_test, rf_predict)
acc <span class="op">=</span> pd.DataFrame(np.array([acc]), columns<span class="op">=</span>[<span class="st">&#39;Accuracy&#39;</span>])
<span class="bu">print</span>(acc)</code></pre>
<pre><code>   Accuracy
0  0.834615</code></pre>
<div id="deep-learning-example-1" class="section level4">
<h4>Deep learning example</h4>
<p>Here is a bit of code to get you started with a scikit approach to deep learning. This is a âdeep neural netâ with seven layers. I also add some âdropoutâ. This isnât too viable a model as far as settings go, and wonât do any better than those shown previously<a href="#fn61" class="footnote-ref" id="fnref61"><sup>61</sup></a>, but itâll run fine on your machine so you can at least play with it.</p>
<pre class="sourceCode python"><code class="sourceCode python"><span class="im">import</span> tensorflow.contrib.learn <span class="im">as</span> skflow
<span class="im">from</span> sklearn <span class="im">import</span> metrics

feats <span class="op">=</span> skflow.infer_real_valued_columns_from_input(X_train)

classifier_tf <span class="op">=</span> skflow.DNNClassifier(feature_columns<span class="op">=</span>feats, 
                                     hidden_units<span class="op">=</span>[<span class="dv">50</span>, <span class="dv">50</span>, <span class="dv">50</span>, <span class="dv">40</span>, <span class="dv">30</span>, <span class="dv">20</span>, <span class="dv">10</span>], 
                                     dropout<span class="op">=</span>.<span class="dv">2</span>,
                                     n_classes<span class="op">=</span><span class="dv">2</span>)
classifier_tf.fit(X_train, y_train, steps<span class="op">=</span><span class="dv">10000</span>)
predictions <span class="op">=</span> <span class="bu">list</span>(classifier_tf.predict(X_test, as_iterable<span class="op">=</span><span class="va">True</span>))
score <span class="op">=</span> metrics.accuracy_score(y_test, predictions)
<span class="bu">print</span>(<span class="st">&quot;Accuracy: </span><span class="sc">%f</span><span class="st">&quot;</span> <span class="op">%</span> score)</code></pre>
</div>
</div>
<div id="other" class="section level3">
<h3>Other</h3>
<p>I wouldnât recommend a proprietary tool when better open source tools are available, but I will say <strong>Matlab</strong> is also very popular in machine learning, and in specific areas like image processing. <strong>Julia</strong> has been coming along as well. Of course, for maximum speed people still prefer lower level languages like <strong>C++</strong>, <strong>Java</strong>, and <strong>Go</strong>, and many of the Python modules are interfaces to such lower-level libraries. And for whatever reason, people are reinventing ML wheels in languages like <strong>Javascript</strong> and others. See the <a href="https://github.com/josephmisiti/awesome-machine-learning">awesome list</a> for more.</p>
<p>What I canât recommend is a traditional statistics package like SPSS, SAS, or Stata. Not only did they miss this boat by well over a decade, their offerings are slim and less capable. It seems SAS is probably the only one thatâs made serious effort here, and it has some audience in the business world due to its long entrenchment there. And you donât have to take my word for it- hereâs a comparison of trends at <a href="https://www.indeed.com/jobtrends/q-R-and-%28%22machine-learning%22-or-%22data-science%22%29-q-python-and-%28%22machine-learning%22-or-%22data-science%22%29-q-SAS-and-%28%22machine-learning%22-or-%22data-science%22%29-q-SPSS-and-%28%22machine-learning%22-or-%22data-science%22%29-q-Stata-and-%28%22machine-learning%22-or-%22data-science%22%29-q-Matlab-and-%28%22machine-learning%22-or-%22data-science%22%29.html">indeed.com</a>.</p>
</div>
</div>
<div id="local-interpretable-model-agnostic-explanations" class="section level2">
<h2>Local Interpretable Model-agnostic Explanations</h2>
<p>The general approach lime takes to achieving this goal is as follows:</p>
<ul>
<li>For each prediction to explain, permute the observations n times<a href="#fn62" class="footnote-ref" id="fnref62"><sup>62</sup></a>.</li>
<li>Let the complex model predict the outcome of all permuted observations.</li>
<li>Calculate the distance from all permutations to the original observation.</li>
<li>Convert the distance to a similarity score.</li>
<li>Select m features best describing the complex model outcome from the permuted data.</li>
<li>Fit a simple model to the permuted data, explaining the complex model outcome with the m features from the permuted data weighted by its similarity to the original observation.</li>
<li>Extract the feature weights from the simple model and use these as explanations for the complex models local behavior.</li>
</ul>
<p>See <span class="citation">Ribeiro, Singh, and Guestrin (<a href="#ref-ribeiro2016">2016</a>)</span> for details.</p>
</div>
<div id="various-variable-importance-measures" class="section level2">
<h2>Various Variable Importance Measures</h2>
<p>This is taken from the <span class="pack">randomForestExplainer</span> package <a href="https://cran.r-project.org/web/packages/randomForestExplainer/vignettes/randomForestExplainer.html">vignette</a>.</p>
<p>For a given predictor variable <span class="math inline">\(X_j\)</span></p>
<ul>
<li><strong>accuracy_decrease</strong> (classification) â mean decrease of prediction accuracy after <span class="math inline">\(X_j\)</span> is permuted</li>
<li><strong>gini_decrease</strong> (classification) â mean decrease in the Gini index of node impurity (i.e.Â increase of node purity) by splits on <span class="math inline">\(X_j\)</span></li>
<li><strong>mse_increase</strong> (regression) â mean increase of mean squared error after <span class="math inline">\(X_j\)</span> is permuted</li>
<li><strong>node_purity_increase</strong> (regression) â mean node purity increase by splits on <span class="math inline">\(X_j\)</span> as measured by the decrease in sum of squares</li>
<li><strong>mean_minimal_depth</strong> â mean minimal depth calculated in one of three ways specified by the parameter mean_sample</li>
<li><strong>no_of_trees</strong> â total number of trees in which a split on <span class="math inline">\(X_j\)</span> occurs</li>
<li><strong>no_of_nodes</strong> â total number of nodes that use <span class="math inline">\(X_j\)</span> for splitting (it is usually equal to no_of_trees if trees are shallow)</li>
<li><strong>times_a_root</strong> â total number of trees in which <span class="math inline">\(X_j\)</span> is used for splitting the root node (i.e., the whole sample is divided into two based on the value of <span class="math inline">\(X_j\)</span>)</li>
<li><p><strong>p_value</strong> â p-value for the one-sided binomial test using the following distribution:</p>
<pre><code>$$\textrm{Binom}(\texttt{no_of_nodes}, P(\textrm{node splits on } X_j)$$

where we calculate the probability of split on $X_j$ as if $X_j$ was uniformly drawn from the $r$ candidate variables

$$P(\textrm{node splits on } X_j)=P(X_j \textrm{ is a candidate}) \cdot P(X_j \textrm{ is selected}) = \frac{r}{p} \cdot \frac{1}{r} = \frac{1}{p}$$

This test tells us whether the observed number of successes (number of nodes in which $X_j$ was used for splitting) exceeds the theoretical number of successes if they were random (i.e. following the binomial distribution given above).</code></pre></li>
</ul>
</div>
<div id="brief-glossary-of-common-terms" class="section level2">
<h2>Brief Glossary of Common Terms</h2>
<p><span class="emph">bias</span>: could mean the intercept (e.g.Â in neural nets), typically refers to the bias in bias-variance decomposition</p>
<p><span class="emph">classifier</span>: specific model or technique (i.e.Â function) that maps observations to classes</p>
<p><span class="emph">confusion matrix</span>: a table of predicted class membership vs.Â true class membership</p>
<p><span class="emph">hypothesis</span>: a specific model <span class="math inline">\(h(x)\)</span> of all possible in the hypothesis space <span class="math inline">\(\mathcal{H}\)</span></p>
<p><span class="emph">input, feature, attribute</span>: independent variable, explanatory variable, covariate, predictor variable, column</p>
<p><span class="emph">instance, example</span>: observation, row</p>
<p><span class="emph">learning</span>: model fitting</p>
<p><span class="emph">machine learning</span>: a form of statistics utilizing various algorithms with a goal to generalize to new data situations</p>
<p><span class="emph">regularization, penalization, shrinkage</span>: The process of adding a penalty to the size of coefficients, thus shrinking them towards zero but resulting in less overfitting (at an increase to bias)</p>
<p><span class="emph">supervised</span>: has a dependent variable</p>
<p><span class="emph">target, label</span>: dependent variable, response, the outcome of interest</p>
<p><span class="emph">unsupervised</span>: no dependent variable (or rather, only dependent variables); think clustering, PCA etc.</p>
<p><span class="emph">weights</span>: coefficients, parameters</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-ribeiro2016">
<p>Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. âWhy Should I Trust You?: Explaining the Predictions of Any Classifier.â In <em>Proceedings of the 22nd Acm Sigkdd International Conference on Knowledge Discovery and Data Mining</em>, 1135â44. ACM.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="59">
<li id="fn59"><p>You can obtain near perfect accuracy on the training set without dropout, but will do no better at test.<a href="appendix.html#fnref59" class="footnote-back">â©</a></p></li>
<li id="fn60"><p>Actually, for this <span class="func">rf.fit</span> was slower than the default <span class="func">randomForest</span> function in R by about a second under similar settings.<a href="appendix.html#fnref60" class="footnote-back">â©</a></p></li>
<li id="fn61"><p>Just for giggles I let that particular one go for 100000 steps and it finally started to get into &gt; 81% on the test set.<a href="appendix.html#fnref61" class="footnote-back">â©</a></p></li>
<li id="fn62"><p>This could be done in different ways. For example, given a numeric feature add some random noise given its place in the distribution of values seen for that feature. In the plots shown, the values, e.g.Â 9.5 and 10.3, are at quantiles (.25 and .5) of the alcohol. The data has been permuted within those quantile bins.<a href="appendix.html#fnref62" class="footnote-back">â©</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="other.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["twitter", "facebook", "google", "weibo", "instapaper"],
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"depth": 2,
"scroll_highlight": true
},
"df_print": "kable",
"highlight": "pygments",
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
