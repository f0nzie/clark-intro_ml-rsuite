# Appendix
 
 
## Bias Variance Demo
 
```{r biasvar_demo, eval=FALSE}
set.seed(123)
x = runif(1000)
ytrue = sin(3*pi*x)
basedat = cbind(x,ytrue)[order(x),]
 
gendatfunc = function(noise=.5, n=1000){
  x = runif(n)
  y = sin(3*pi*x) + rnorm(n, sd=noise) # truth
  d = cbind(x, y)
  d
}
 
gendat = replicate(100, gendatfunc(n=100))
str(gendat)
 
library(kernlab)
 
rbf1 = apply(gendat, 3, 
             function(d) predict(gausspr(y~x, data=data.frame(d), kpar=list(sigma=.5)), 
                                 newdata = data.frame(x), type='response'))
rbf2 = apply(gendat, 3, 
             function(d) predict(gausspr(y~x, data=data.frame(d)), 
                                 newdata = data.frame(x), type='response') )
 
library(ggplot2); library(tidyverse); library(gridExtra)
 
rbf1_samp = rbf1 %>% 
  data.frame %>% 
  cbind(x, .) %>%
  slice(sample(1:100, 25)) %>% 
  gather(key=sample, value=yhat, -x)
 
rbf2_samp = rbf2 %>% 
  data.frame %>% 
  cbind(x, .) %>%
  slice(sample(1:100, 25)) %>% 
  gather(key=sample, value=yhat, -x)
 
g1 = ggplot(data=data.frame(basedat)) +
  geom_blank() +
  geom_line(aes(x=x, y=yhat, group=sample), color='#ff5500', alpha=.25, data=rbf1_samp) +
  ylim(c(-1.5, 1.5)) +
  labs(y='', title='Low Variance') + 
  lazerhawk::theme_trueMinimal() +
    theme(
    legend.key = ggplot2::element_rect(fill='#fffff8', colour = NA),
    legend.background = ggplot2::element_rect(fill='#fffff8', colour = NA),
    panel.background = ggplot2::element_blank(),
    panel.grid = ggplot2::element_blank(),
    strip.background = ggplot2::element_blank(),
    plot.background = ggplot2::element_rect(fill = "#fffff8", colour = NA)
  )
 
g2 = ggplot(data=data.frame(basedat)) +
  geom_line(aes(x=x, y=ytrue), color='#00aaff') +
  geom_line(aes(x=x, y=yhat), color='#ff5500', data.frame(yhat=rowMeans(rbf1))) +
  ylim(c(-1.5, 1.5)) +
  labs(y='', title='High Bias') + 
  lazerhawk::theme_trueMinimal() +
    theme(
    legend.key = ggplot2::element_rect(fill='#fffff8', colour = NA),
    legend.background = ggplot2::element_rect(fill='#fffff8', colour = NA),
    panel.background = ggplot2::element_blank(),
    panel.grid = ggplot2::element_blank(),
    strip.background = ggplot2::element_blank(),
    plot.background = ggplot2::element_rect(fill = "#fffff8", colour = NA)
  )
 
g3 = ggplot(data=data.frame(basedat)) +
  geom_blank() +
  geom_line(aes(x=x, y=yhat, group=sample), color='#ff5500', alpha=.25, data=rbf2_samp) +
    ylim(c(-1.5, 1.5)) +
  labs(y='', title='High Variance') + 
  lazerhawk::theme_trueMinimal() +
    theme(
    legend.key = ggplot2::element_rect(fill='#fffff8', colour = NA),
    legend.background = ggplot2::element_rect(fill='#fffff8', colour = NA),
    panel.background = ggplot2::element_blank(),
    panel.grid = ggplot2::element_blank(),
    strip.background = ggplot2::element_blank(),
    plot.background = ggplot2::element_rect(fill = "#fffff8", colour = NA)
  )
 
g4 = ggplot(data=data.frame(basedat)) +
  geom_line(aes(x=x, y=ytrue), color='#00aaff') +
  geom_line(aes(x=x, y=yhat), color='#ff5500', data.frame(yhat=rowMeans(rbf2))) +
  ylim(c(-1.5, 1.5)) +
  labs(y='', title='Low Bias') + 
  lazerhawk::theme_trueMinimal() +
    theme(
    legend.key = ggplot2::element_rect(fill='#fffff8', colour = NA),
    legend.background = ggplot2::element_rect(fill='#fffff8', colour = NA),
    panel.background = ggplot2::element_blank(),
    panel.grid = ggplot2::element_blank(),
    strip.background = ggplot2::element_blank(),
    plot.background = ggplot2::element_rect(fill = "#fffff8", colour = NA)
  )
 
grid.arrange(g1, g2, g3, g4, ncol=2)
```
 
 
 
## Programming Languages
 
### R

Demonstrations for this document were done with R, and specifically the <span class="pack">caret</span> package. I would highly recommend using it for your own needs, as it makes a lot the ML process simpler, while providing access to whatever technique you want to use, even while it comes with the ability to use hundreds of approaches out of the box.  

#### Deep learning example

The following is a deep learning example using the same data from the previous examples, using <span class="pack">keras</span>.  The package is an R wrapper for the <span class="pack">keras</span> module in Python, which itself is a wrapper for <span class="pack">tensorflow</span>.  For more on using TensorFlow with R, check out [RStudio's documentation](https://tensorflow.rstudio.com/).

This is a <span class="emph">sequential neural net</span> with three layers.  I also add some <span class="emph">dropout</span> at each layer, which, given the material presented, you can think of as a means of regularization to avoid overfitting[^onepointo].  Note that keras works a bit differently, in that its objects are mutable, hence the there is no reassignment of the <span class="objclass">model</span>.  This R implementation also provides some nice visualizations to keep your interest while it runs. 

This is just a starting point, so don't expect any better performance than those shown previously, but it'll give you something to play with. Note that there is plenty to learn, and such models require copious amounts of tuning to work well.

```{r rdl, eval=FALSE}
library(keras)

X_train = model.matrix(lm(good ~ . -1, data=wine_train)) %>% scale()
y_train = as.numeric(wine_train$good) - 1
X_test = model.matrix(lm(good ~ . -1, data=wine_test)) %>% scale()
y_test = as.numeric(wine_test$good) - 1

model = keras_model_sequential() 

model %>%
  layer_dense(units = 256, activation = 'relu', input_shape = c(9)) %>%
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units = 128, activation = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 64, activation = 'relu') %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 1, activation = 'sigmoid')

summary(model)

model %>% compile(
  optimizer = 'nadam',
  loss = "binary_crossentropy",
  metrics = "accuracy"
)

history = model %>% 
  fit(X_train, 
      y_train, 
      epochs = 10000, 
      validation_split = 0.1,
      verbose = 1,
      view_metrics = 1)

plot(history)

# model %>% evaluate(X_test, y_test)

ypred = model %>% predict_classes(X_test)
caret::confusionMatrix(ypred, y_test, positive='1')
```




### Python

If your data fits on your machine and/or your analysis time is less than a couple hours, R is hands down the easiest to use to go from data to document, including if that document is an interactive website.  That said, R probably isn't even the most popular ML tool, because in many situations we have a lot more data, or simply need the predictions without frills and as fast as possible[^rfaster].  As such Python is the de facto standard in such situations, and probably the most popular development environment for machine learning.

One can start with the <span class="pack">scikit-learn</span> module, using it much in the same way as was demonstrated with <span class="pack">caret</span>.  It will get you very far, but for some situations, you may need more heavy-duty options like <span class="pack">tensorflow</span>, <span class="pack">pytorch</span>, etc.

<!-- Though no change was made to the code, nor any need to re-evaluate what was alrady displayed, something caused knitr to do so and empty lines are now ignored; separate chunks until fixed -->

```{python pyrf, engine.path= '/Users/micl/anaconda3/bin/python',  eval=T, cache=TRUE}
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score
# from os import chdir            # if desired
# chdir('your_directory')
```

```{python pyrf_import}
# import data
wine = pd.read_csv('data/wine.csv')
```

```{python pyrf_dataproc}
# data preprocessing
np.random.seed(1234)
X = wine.drop(['free.sulfur.dioxide', 'density', 'quality', 'color', 'white','good'], axis=1)
X = MinMaxScaler().fit_transform(X)  # by default on 0, 1 scale
y = wine['good']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```
```{python pyrf_2_train}
# train model
rf = RandomForestClassifier(n_estimators=1000)
rf_train = rf.fit(X_train, y_train)
```
```{python pyrf_test}
# get test predictions
rf_predict = rf_train.predict(X_test)
```
```{python pyrf_assess}
# create confusion matrix, and accuracy
cm = confusion_matrix(y_test,rf_predict)
cm_prob = cm / np.sum(cm)  # as probs
print(cm_prob)
```
```{python pyrf2}
acc = accuracy_score(y_test, rf_predict)
acc = pd.DataFrame(np.array([acc]), columns=['Accuracy'])
print(acc)
```



#### Deep learning example

Here is a bit of code to get you started with a scikit approach to deep learning. This is a 'deep neural net' with seven layers.  I also add some 'dropout'.  This isn't too viable a model as far as settings go, and won't do any better than those shown previously[^dnn], but it'll run fine on your machine so you can at least play with it.

```{python dl, eval=F}
import tensorflow.contrib.learn as skflow
from sklearn import metrics

feats = skflow.infer_real_valued_columns_from_input(X_train)

classifier_tf = skflow.DNNClassifier(feature_columns=feats, 
                                     hidden_units=[50, 50, 50, 40, 30, 20, 10], 
                                     dropout=.2,
                                     n_classes=2)
classifier_tf.fit(X_train, y_train, steps=10000)
predictions = list(classifier_tf.predict(X_test, as_iterable=True))
score = metrics.accuracy_score(y_test, predictions)
print("Accuracy: %f" % score)
```


### Other

I wouldn't recommend a proprietary tool when better open source tools are available, but I will say **Matlab** is also very popular in machine learning, and in specific areas like image processing. **Julia** has been coming along as well.  Of course, for maximum speed people still prefer lower level languages like **C++**, **Java**, and **Go**, and many of the Python modules are interfaces to such lower-level libraries. And for whatever reason, people are reinventing ML wheels in languages like **Javascript** and others.  See the [awesome list](https://github.com/josephmisiti/awesome-machine-learning) for more.

What I can't recommend is a traditional statistics package like SPSS, SAS, or Stata. Not only did they miss this boat by well over a decade, their offerings are slim and less capable.  It seems SAS is probably the only one that's made serious effort here, and it has some audience in the business world due to its long entrenchment there.  And you don't have to take my word for it- here's a comparison of trends at [indeed.com](https://www.indeed.com/jobtrends/q-R-and-%28%22machine-learning%22-or-%22data-science%22%29-q-python-and-%28%22machine-learning%22-or-%22data-science%22%29-q-SAS-and-%28%22machine-learning%22-or-%22data-science%22%29-q-SPSS-and-%28%22machine-learning%22-or-%22data-science%22%29-q-Stata-and-%28%22machine-learning%22-or-%22data-science%22%29-q-Matlab-and-%28%22machine-learning%22-or-%22data-science%22%29.html).


## Local Interpretable Model-agnostic Explanations

The general approach lime takes to achieving this goal is as follows:

- For each prediction to explain, permute the observations n times[^rf_lime_permute].
- Let the complex model predict the outcome of all permuted observations.
- Calculate the distance from all permutations to the original observation.
- Convert the distance to a similarity score.
- Select m features best describing the complex model outcome from the permuted data.
- Fit a simple model to the permuted data, explaining the complex model outcome with the m features from the permuted data weighted by its similarity to the original observation.
- Extract the feature weights from the simple model and use these as explanations for the complex models local behavior.

See @ribeiro2016 for details.


## Various Variable Importance Measures

This is taken from the <span class="pack">randomForestExplainer</span> package [vignette](https://cran.r-project.org/web/packages/randomForestExplainer/vignettes/randomForestExplainer.html).

For a given predictor variable $X_j$

- **accuracy_decrease** (classification) – mean decrease of prediction accuracy after $X_j$ is permuted
- **gini_decrease** (classification) – mean decrease in the Gini index of node impurity (i.e. increase of node purity) by splits on $X_j$
- **mse_increase** (regression) – mean increase of mean squared error after $X_j$ is permuted
- **node_purity_increase** (regression) – mean node purity increase by splits on $X_j$ as measured by the decrease in sum of squares
- **mean_minimal_depth** – mean minimal depth calculated in one of three ways specified by the parameter mean_sample
- **no_of_trees** – total number of trees in which a split on $X_j$ occurs
- **no_of_nodes** – total number of nodes that use $X_j$ for splitting (it is usually equal to no_of_trees if trees are shallow)
- **times_a_root** – total number of trees in which $X_j$ is used for splitting the root node (i.e., the whole sample is divided into two based on the value of $X_j$)
- **p_value** – p-value for the one-sided binomial test using the following distribution:

      $$\textrm{Binom}(\texttt{no_of_nodes}, P(\textrm{node splits on } X_j)$$
      
      where we calculate the probability of split on $X_j$ as if $X_j$ was uniformly drawn from the $r$ candidate variables
      
      $$P(\textrm{node splits on } X_j)=P(X_j \textrm{ is a candidate}) \cdot P(X_j \textrm{ is selected}) = \frac{r}{p} \cdot \frac{1}{r} = \frac{1}{p}$$
      
      This test tells us whether the observed number of successes (number of nodes in which $X_j$ was used for splitting) exceeds the theoretical number of successes if they were random (i.e. following the binomial distribution given above).

## Brief Glossary of Common Terms


<span class="emph">bias</span>: could mean the intercept (e.g. in neural nets), typically refers to the bias in bias-variance decomposition

<span class="emph">classifier</span>: specific model or technique (i.e. function) that maps observations to classes

<span class="emph">confusion matrix</span>: a table of predicted class membership vs. true class membership

<span class="emph">hypothesis</span>: a specific model $h(x)$ of all possible in the hypothesis space $\mathcal{H}$

<span class="emph">input, feature, attribute</span>: independent variable, explanatory variable, covariate, predictor variable, column

<span class="emph">instance, example</span>: observation, row

<span class="emph">learning</span>: model fitting

<span class="emph">machine learning</span>: a form of statistics utilizing various algorithms with a goal to generalize to new data situations

<span class="emph">regularization, penalization, shrinkage</span>: The process of adding a penalty to the size of coefficients, thus shrinking them towards zero but resulting in less overfitting (at an increase to bias)

<span class="emph">supervised</span>: has a dependent variable

<span class="emph">target, label</span>: dependent variable, response, the outcome of interest

<span class="emph">unsupervised</span>: no dependent variable (or rather, only dependent variables); think clustering, PCA etc.

<span class="emph">weights</span>:  coefficients, parameters



[^rfaster]: Actually, for this <span class="func">rf.fit</span> was slower than the default <span class="func">randomForest</span> function in R by about a second under similar settings.

[^dnn]: Just for giggles I let that particular one go for 100000 steps and it finally started to get into > 81% on the test set. 

[^onepointo]: You can obtain near perfect accuracy on the training set without dropout, but will do no better at test.